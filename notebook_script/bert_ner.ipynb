{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, AdamW\n",
    "\n",
    "from dataset.dataset import collate_fn, DuEEEventDataset\n",
    "from metric.metric import ChunkEvaluator\n",
    "from model.model import DuEEEvent_model\n",
    "from utils.finetuning_argparse import get_argparse\n",
    "from utils.utils import init_logger, seed_everything, logger, ProgressBar\n",
    "\n",
    "\n",
    "def evaluate(args, eval_iter, model, metric):\n",
    "    \"\"\"evaluate\"\"\"\n",
    "    metric.reset()\n",
    "    batch_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1).to(args.device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(eval_iter):\n",
    "            \n",
    "            for key in batch.keys():\n",
    "                batch[key] = batch[key].to(args.device)\n",
    "            logits = model(\n",
    "                input_ids=batch['all_input_ids'],\n",
    "                attention_mask=batch['all_attention_mask'],\n",
    "                token_type_ids=batch['all_token_type_ids']\n",
    "            )\n",
    "            #loss = criterion(logits.view(-1, args.num_classes),batch[\"all_labels\"].view(-1))\n",
    "            #batch_loss += loss.item()\n",
    "\n",
    "            \n",
    "            #preds = torch.argmax(logits, axis=-1)\n",
    "            preds=torch.tensor(model.crf.decode(logits),dtype=torch.int)\n",
    "            n_infer, n_label, n_correct = metric.compute(batch[\"all_seq_lens\"], preds, batch['all_labels'])\n",
    "            metric.update(n_infer, n_label, n_correct)\n",
    "\n",
    "    precision, recall, f1_score = metric.accumulate()\n",
    "\n",
    "    return precision, recall, f1_score, batch_loss / (step + 1)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_argparse().parse_args()\n",
    "    print(json.dumps(vars(args), sort_keys=True, indent=4, separators=(', ', ': '), ensure_ascii=False))\n",
    "    init_logger(log_file=\"./log/{}.log\".format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())))\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    args.output_model_path = os.path.join(args.output_dir, args.dataset, args.event_type, \"best_model.pkl\")\n",
    "    # 设置保存目录\n",
    "    if not os.path.exists(os.path.dirname(args.output_model_path)):\n",
    "        os.makedirs(os.path.dirname(args.output_model_path))\n",
    "\n",
    "    # device\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "    # dataset & dataloader\n",
    "    args.train_data = \"./data/{}/{}/train.tsv\".format(args.dataset, args.event_type)\n",
    "    args.dev_data = \"./data/{}/{}/dev.tsv\".format(args.dataset, args.event_type)\n",
    "    args.tag_path = \"./conf/{}/{}_tag.dict\".format(args.dataset, args.event_type)\n",
    "    train_dataset = DuEEEventDataset(args,\n",
    "                                     args.train_data,\n",
    "                                     args.tag_path,\n",
    "                                     tokenizer)\n",
    "    eval_dataset = DuEEEventDataset(args,\n",
    "                                    args.dev_data,\n",
    "                                    args.tag_path,\n",
    "                                    tokenizer)\n",
    "    logger.info(\"The nums of the train_dataset features is {}\".format(len(train_dataset)))\n",
    "    logger.info(\"The nums of the eval_dataset features is {}\".format(len(eval_dataset)))\n",
    "    train_iter = DataLoader(train_dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args.per_gpu_train_batch_size,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=20)\n",
    "    eval_iter = DataLoader(eval_dataset,\n",
    "                           shuffle=False,\n",
    "                           batch_size=args.per_gpu_eval_batch_size,\n",
    "                           collate_fn=collate_fn,\n",
    "                           num_workers=20)\n",
    "\n",
    "    # 用于evaluate\n",
    "    args.id2label = train_dataset.label_vocab\n",
    "    args.num_classes = len(args.id2label)\n",
    "    metric = ChunkEvaluator(label_list=args.id2label.keys(), suffix=False)\n",
    "\n",
    "    # model\n",
    "    model = DuEEEvent_model(args.model_name_or_path, num_classes=args.num_classes)\n",
    "    model.to(args.device)\n",
    "\n",
    "    best_f1 = 0\n",
    "    early_stop = 0\n",
    "    for epoch, _ in enumerate(range(int(args.num_train_epochs))):\n",
    "        model.train()\n",
    "        train(args, train_iter, model)\n",
    "        eval_p, eval_r, eval_f1, eval_loss = evaluate(args, eval_iter, model, metric)\n",
    "        logger.info(\n",
    "            \"The F1-score is {}\".format(eval_f1)\n",
    "        )\n",
    "        if eval_f1 > best_f1:\n",
    "            early_stop = 0\n",
    "            best_f1 = eval_f1\n",
    "            logger.info(\"the best eval f1 is {:.4f}, saving model !!\".format(best_f1))\n",
    "            best_model = copy.deepcopy(model.module if hasattr(model, \"module\") else model)\n",
    "            torch.save(best_model.state_dict(), args.output_model_path)\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop == args.early_stop:\n",
    "                logger.info(\"Early stop in {} epoch!\".format(epoch))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_iter, model):\n",
    "    logger.info(\"***** Running train *****\")\n",
    "    # 优化器\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    bert_param_optimizer = list(model.bert.named_parameters())\n",
    "    linear_param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in bert_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay,\n",
    "         'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in bert_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0,\n",
    "         'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in linear_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay,\n",
    "         'lr': args.linear_learning_rate},\n",
    "        {'params': [p for n, p in linear_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0,\n",
    "         'lr': args.linear_learning_rate},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=args.learning_rate,\n",
    "                      eps=args.adam_epsilon)\n",
    "    # 损失函数\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1).to(args.device)\n",
    "    batch_loss = 0\n",
    "    pbar = ProgressBar(n_total=len(train_iter), desc='Training')\n",
    "    print(\"****\" * 20)\n",
    "    for step, batch in enumerate(train_iter):\n",
    "        for key in batch.keys():\n",
    "            batch[key] = batch[key].to(args.device)\n",
    "        logits = model(\n",
    "            input_ids=batch['all_input_ids'],\n",
    "            attention_mask=batch['all_attention_mask'],\n",
    "            token_type_ids=batch['all_token_type_ids'],\n",
    "            labels=batch['all_labels']\n",
    "        )\n",
    "        #logits = logits.view(-1, args.num_classes)\n",
    "        # 正常训练\n",
    "        #loss = criterion(logits, batch[\"all_labels\"].view(-1))\n",
    "        loss=logits\n",
    "        loss.backward()\n",
    "        #\n",
    "        batch_loss += loss.item()\n",
    "        pbar(step,\n",
    "             {\n",
    "                 'batch_loss': batch_loss / (step + 1),\n",
    "             })\n",
    "        optimizer.step()\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self):\n",
    "        self.dataset='DuEE1.0'\n",
    "        self.event_type='role'\n",
    "        self.max_len=200\n",
    "        self.per_gpu_train_batch_size=16\n",
    "        self.per_gpu_eval_batch_size=32\n",
    "        #self.model_name_or_path='F:/prev_trained_model/rbt3'\n",
    "        self.model_name_or_path='F:/prev_trained_model/chinese_wwm_pytorch'\n",
    "        self.linear_learning_rate=1e-4\n",
    "        self.early_stop=5\n",
    "        self.seed=1\n",
    "        self.output_dir='../output'\n",
    "        self.num_train_epochs=50\n",
    "        self.weight_decay=0.01\n",
    "        self.learning_rate=1e-5\n",
    "        self.adam_epsilon=1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"adam_epsilon\": 1e-08, \n",
      "    \"dataset\": \"DuEE1.0\", \n",
      "    \"early_stop\": 5, \n",
      "    \"event_type\": \"role\", \n",
      "    \"learning_rate\": 1e-05, \n",
      "    \"linear_learning_rate\": 0.0001, \n",
      "    \"max_len\": 200, \n",
      "    \"model_name_or_path\": \"F:/prev_trained_model/chinese_wwm_pytorch\", \n",
      "    \"num_train_epochs\": 50, \n",
      "    \"output_dir\": \"../output\", \n",
      "    \"per_gpu_eval_batch_size\": 32, \n",
      "    \"per_gpu_train_batch_size\": 16, \n",
      "    \"seed\": 1, \n",
      "    \"weight_decay\": 0.01\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing...: 100%|███████████████████████████████████████████████████████████| 13915/13915 [00:09<00:00, 1520.62it/s]\n",
      "tokenizing...: 100%|█████████████████████████████████████████████████████████████| 1790/1790 [00:01<00:00, 1498.44it/s]\n",
      "05/14/2021 10:00:37 - INFO - root -   The nums of the train_dataset features is 13915\n",
      "05/14/2021 10:00:37 - INFO - root -   The nums of the eval_dataset features is 1790\n"
     ]
    }
   ],
   "source": [
    "args=CFG()\n",
    "\n",
    "print(json.dumps(vars(args), sort_keys=True, indent=4, separators=(', ', ': '), ensure_ascii=False))\n",
    "init_logger(log_file=\".././log/{}.log\".format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())))\n",
    "seed_everything(args.seed)\n",
    "\n",
    "args.output_model_path = os.path.join(args.output_dir, args.dataset, args.event_type, \"best_model.pkl\")\n",
    "# 设置保存目录\n",
    "if not os.path.exists(os.path.dirname(args.output_model_path)):\n",
    "    os.makedirs(os.path.dirname(args.output_model_path))\n",
    "\n",
    "# device\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# dataset & dataloader\n",
    "args.train_data = \"../data/{}/{}/train.tsv\".format(args.dataset, args.event_type)\n",
    "args.dev_data = \"../data/{}/{}/dev.tsv\".format(args.dataset, args.event_type)\n",
    "args.tag_path = \"../conf/{}/{}_tag.dict\".format(args.dataset, args.event_type)\n",
    "train_dataset = DuEEEventDataset(args,\n",
    "                                 args.train_data,\n",
    "                                 args.tag_path,\n",
    "                                 tokenizer)\n",
    "eval_dataset = DuEEEventDataset(args,\n",
    "                                args.dev_data,\n",
    "                                args.tag_path,\n",
    "                                tokenizer)\n",
    "logger.info(\"The nums of the train_dataset features is {}\".format(len(train_dataset)))\n",
    "logger.info(\"The nums of the eval_dataset features is {}\".format(len(eval_dataset)))\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=args.per_gpu_train_batch_size,\n",
    "                        collate_fn=collate_fn,\n",
    "                        num_workers=0)\n",
    "eval_iter = DataLoader(eval_dataset,\n",
    "                       shuffle=False,\n",
    "                       batch_size=args.per_gpu_eval_batch_size,\n",
    "                       collate_fn=collate_fn,\n",
    "                       num_workers=0)\n",
    "\n",
    "# 用于evaluate\n",
    "args.id2label = train_dataset.label_vocab\n",
    "args.num_classes = len(args.id2label)\n",
    "metric = ChunkEvaluator(label_list=args.id2label.keys(), suffix=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "class DuEEEvent_crf_model(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_classes):\n",
    "        super(DuEEEvent_crf_model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_path)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        self.crf = CRF(num_tags=num_classes, batch_first=True)\n",
    "        \n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=None,\n",
    "                labels=None):\n",
    "        output = self.bert(input_ids,\n",
    "                           token_type_ids=token_type_ids,\n",
    "                           attention_mask=attention_mask)\n",
    "        sequence_output, pooled_output = output[0], output[1]\n",
    "        logits = self.classifier(sequence_output)\n",
    "        if labels is not None:\n",
    "            loss = self.crf(emissions=logits, tags=labels, mask=attention_mask.to(torch.uint8))\n",
    "            return -1 * loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DuEEEvent_crf_model(args.model_name_or_path, num_classes=args.num_classes)\n",
    "_=model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:00:40 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 771.0ms/step  batch_loss: 783.9935 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:12:26 - INFO - root -   The F1-score is 0.41931034482758617\n",
      "05/14/2021 10:12:26 - INFO - root -   the best eval f1 is 0.4193, saving model !!\n",
      "05/14/2021 10:12:26 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 774.9ms/step  batch_loss: 338.4136 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:24:16 - INFO - root -   The F1-score is 0.5091200641411104\n",
      "05/14/2021 10:24:16 - INFO - root -   the best eval f1 is 0.5091, saving model !!\n",
      "05/14/2021 10:24:17 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 774.5ms/step  batch_loss: 257.6888 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:36:05 - INFO - root -   The F1-score is 0.5408596582081823\n",
      "05/14/2021 10:36:05 - INFO - root -   the best eval f1 is 0.5409, saving model !!\n",
      "05/14/2021 10:36:06 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 774.1ms/step  batch_loss: 213.5546 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:47:55 - INFO - root -   The F1-score is 0.5639467895674034\n",
      "05/14/2021 10:47:55 - INFO - root -   the best eval f1 is 0.5639, saving model !!\n",
      "05/14/2021 10:47:56 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 771.2ms/step  batch_loss: 184.4019 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 10:59:42 - INFO - root -   The F1-score is 0.564465567802609\n",
      "05/14/2021 10:59:42 - INFO - root -   the best eval f1 is 0.5645, saving model !!\n",
      "05/14/2021 10:59:43 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 783.0ms/step  batch_loss: 162.4229 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 11:11:39 - INFO - root -   The F1-score is 0.5718705115456855\n",
      "05/14/2021 11:11:39 - INFO - root -   the best eval f1 is 0.5719, saving model !!\n",
      "05/14/2021 11:11:40 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 780.8ms/step  batch_loss: 145.2762 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 11:23:34 - INFO - root -   The F1-score is 0.5833153696917439\n",
      "05/14/2021 11:23:34 - INFO - root -   the best eval f1 is 0.5833, saving model !!\n",
      "05/14/2021 11:23:35 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 777.9ms/step  batch_loss: 131.1192 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 11:35:28 - INFO - root -   The F1-score is 0.5883342091434577\n",
      "05/14/2021 11:35:28 - INFO - root -   the best eval f1 is 0.5883, saving model !!\n",
      "05/14/2021 11:35:29 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 778.2ms/step  batch_loss: 119.6425 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 11:47:20 - INFO - root -   The F1-score is 0.5915314935748893\n",
      "05/14/2021 11:47:20 - INFO - root -   the best eval f1 is 0.5915, saving model !!\n",
      "05/14/2021 11:47:21 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 781.4ms/step  batch_loss: 110.7582 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 11:59:16 - INFO - root -   The F1-score is 0.5912639797425617\n",
      "05/14/2021 11:59:16 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 778.4ms/step  batch_loss: 102.1600 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 12:11:08 - INFO - root -   The F1-score is 0.5826972010178118\n",
      "05/14/2021 12:11:08 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 778.5ms/step  batch_loss: 97.9461 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 12:23:00 - INFO - root -   The F1-score is 0.6014619582003501\n",
      "05/14/2021 12:23:00 - INFO - root -   the best eval f1 is 0.6015, saving model !!\n",
      "05/14/2021 12:23:01 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 779.6ms/step  batch_loss: 89.3468 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 12:34:54 - INFO - root -   The F1-score is 0.6021867115222876\n",
      "05/14/2021 12:34:54 - INFO - root -   the best eval f1 is 0.6022, saving model !!\n",
      "05/14/2021 12:34:55 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 769.4ms/step  batch_loss: 85.9298 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 12:46:39 - INFO - root -   The F1-score is 0.5878974358974358\n",
      "05/14/2021 12:46:39 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 767.9ms/step  batch_loss: 80.6828 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 12:58:22 - INFO - root -   The F1-score is 0.6049395691014188\n",
      "05/14/2021 12:58:22 - INFO - root -   the best eval f1 is 0.6049, saving model !!\n",
      "05/14/2021 12:58:23 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 776.7ms/step  batch_loss: 77.3345 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 13:10:13 - INFO - root -   The F1-score is 0.6113490364025697\n",
      "05/14/2021 13:10:13 - INFO - root -   the best eval f1 is 0.6113, saving model !!\n",
      "05/14/2021 13:10:14 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 771.6ms/step  batch_loss: 73.5488 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 13:22:00 - INFO - root -   The F1-score is 0.6011986121333193\n",
      "05/14/2021 13:22:00 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 776.7ms/step  batch_loss: 72.9709 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 13:33:51 - INFO - root -   The F1-score is 0.604502973661852\n",
      "05/14/2021 13:33:51 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 777.1ms/step  batch_loss: 67.2790 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 13:45:42 - INFO - root -   The F1-score is 0.6046314000424899\n",
      "05/14/2021 13:45:42 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 792.6ms/step  batch_loss: 66.8107 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 13:57:47 - INFO - root -   The F1-score is 0.614572333685322\n",
      "05/14/2021 13:57:47 - INFO - root -   the best eval f1 is 0.6146, saving model !!\n",
      "05/14/2021 13:57:47 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 778.1ms/step  batch_loss: 64.6178 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 14:09:39 - INFO - root -   The F1-score is 0.6020493517356754\n",
      "05/14/2021 14:09:39 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 789.3ms/step  batch_loss: 64.0051 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 14:21:41 - INFO - root -   The F1-score is 0.6161007087697027\n",
      "05/14/2021 14:21:41 - INFO - root -   the best eval f1 is 0.6161, saving model !!\n",
      "05/14/2021 14:21:42 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 777.1ms/step  batch_loss: 61.4700 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 14:33:33 - INFO - root -   The F1-score is 0.6045250755917005\n",
      "05/14/2021 14:33:33 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 784.0ms/step  batch_loss: 59.9681 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 14:45:31 - INFO - root -   The F1-score is 0.6129372102823429\n",
      "05/14/2021 14:45:31 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 789.5ms/step  batch_loss: 58.0776 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 14:57:33 - INFO - root -   The F1-score is 0.6094276094276094\n",
      "05/14/2021 14:57:33 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 786.9ms/step  batch_loss: 57.3843 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 15:09:33 - INFO - root -   The F1-score is 0.6069544622671977\n",
      "05/14/2021 15:09:33 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 794.8ms/step  batch_loss: 55.7698 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/14/2021 15:21:41 - INFO - root -   The F1-score is 0.603099173553719\n",
      "05/14/2021 15:21:41 - INFO - root -   Early stop in 26 epoch!\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "early_stop = 0\n",
    "for epoch, _ in enumerate(range(int(args.num_train_epochs))):\n",
    "    model.train()\n",
    "    train(args, train_iter, model)\n",
    "    eval_p, eval_r, eval_f1, eval_loss = evaluate(args, eval_iter, model, metric)\n",
    "    logger.info(\n",
    "        \"The F1-score is {}\".format(eval_f1)\n",
    "    )\n",
    "    if eval_f1 > best_f1:\n",
    "        early_stop = 0\n",
    "        best_f1 = eval_f1\n",
    "        logger.info(\"the best eval f1 is {:.4f}, saving model !!\".format(best_f1))\n",
    "        best_model = copy.deepcopy(model.module if hasattr(model, \"module\") else model)\n",
    "        torch.save(best_model.state_dict(), args.output_model_path)\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == args.early_stop:\n",
    "            logger.info(\"Early stop in {} epoch!\".format(epoch))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
