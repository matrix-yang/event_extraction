{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    def __init__(self):\n",
    "        self.dataset='DuEE1.0'\n",
    "        self.event_type='trigger'\n",
    "        self.max_len=200\n",
    "        self.per_gpu_train_batch_size=16\n",
    "        self.per_gpu_eval_batch_size=32\n",
    "        self.model_name_or_path='F:/prev_trained_model/chinese_wwm_pytorch'\n",
    "        #self.model_name_or_path='F:/prev_trained_model/rbt3'\n",
    "        self.linear_learning_rate=1e-4\n",
    "        self.early_stop=5\n",
    "        self.seed=1\n",
    "        self.output_dir='../output'\n",
    "        self.num_train_epochs=50\n",
    "        self.weight_decay=0.01\n",
    "        self.learning_rate=1e-5\n",
    "        self.adam_epsilon=1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, AdamW\n",
    "\n",
    "from dataset.dataset import joint_collate_fn,DuEEJointDataset\n",
    "from metric.metric import ChunkEvaluator\n",
    "from model.model import DuEEEvent_model\n",
    "from utils.finetuning_argparse import get_argparse\n",
    "from utils.utils import init_logger, seed_everything, logger, ProgressBar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_argparse().parse_args()\n",
    "    print(json.dumps(vars(args), sort_keys=True, indent=4, separators=(', ', ': '), ensure_ascii=False))\n",
    "    init_logger(log_file=\"./log/{}.log\".format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())))\n",
    "    seed_everything(args.seed)\n",
    "\n",
    "    args.output_model_path = os.path.join(args.output_dir, args.dataset, args.event_type, \"best_model.pkl\")\n",
    "    # 设置保存目录\n",
    "    if not os.path.exists(os.path.dirname(args.output_model_path)):\n",
    "        os.makedirs(os.path.dirname(args.output_model_path))\n",
    "\n",
    "    # device\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "    # dataset & dataloader\n",
    "    args.train_data = \"./data/{}/{}/train.tsv\".format(args.dataset, args.event_type)\n",
    "    args.dev_data = \"./data/{}/{}/dev.tsv\".format(args.dataset, args.event_type)\n",
    "    args.tag_path = \"./conf/{}/{}_tag.dict\".format(args.dataset, args.event_type)\n",
    "    train_dataset = DuEEEventDataset(args,\n",
    "                                     args.train_data,\n",
    "                                     args.tag_path,\n",
    "                                     tokenizer)\n",
    "    eval_dataset = DuEEEventDataset(args,\n",
    "                                    args.dev_data,\n",
    "                                    args.tag_path,\n",
    "                                    tokenizer)\n",
    "    logger.info(\"The nums of the train_dataset features is {}\".format(len(train_dataset)))\n",
    "    logger.info(\"The nums of the eval_dataset features is {}\".format(len(eval_dataset)))\n",
    "    train_iter = DataLoader(train_dataset,\n",
    "                            shuffle=True,\n",
    "                            batch_size=args.per_gpu_train_batch_size,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=20)\n",
    "    eval_iter = DataLoader(eval_dataset,\n",
    "                           shuffle=False,\n",
    "                           batch_size=args.per_gpu_eval_batch_size,\n",
    "                           collate_fn=collate_fn,\n",
    "                           num_workers=20)\n",
    "\n",
    "    # 用于evaluate\n",
    "    args.id2label = train_dataset.label_vocab\n",
    "    args.num_classes = len(args.id2label)\n",
    "    metric = ChunkEvaluator(label_list=args.id2label.keys(), suffix=False)\n",
    "\n",
    "    # model\n",
    "    model = DuEEEvent_model(args.model_name_or_path, num_classes=args.num_classes)\n",
    "    model.to(args.device)\n",
    "\n",
    "    best_f1 = 0\n",
    "    early_stop = 0\n",
    "    for epoch, _ in enumerate(range(int(args.num_train_epochs))):\n",
    "        model.train()\n",
    "        train(args, train_iter, model)\n",
    "        eval_p, eval_r, eval_f1, eval_loss = evaluate(args, eval_iter, model, metric)\n",
    "        logger.info(\n",
    "            \"The F1-score is {}\".format(eval_f1)\n",
    "        )\n",
    "        if eval_f1 > best_f1:\n",
    "            early_stop = 0\n",
    "            best_f1 = eval_f1\n",
    "            logger.info(\"the best eval f1 is {:.4f}, saving model !!\".format(best_f1))\n",
    "            best_model = copy.deepcopy(model.module if hasattr(model, \"module\") else model)\n",
    "            torch.save(best_model.state_dict(), args.output_model_path)\n",
    "        else:\n",
    "            early_stop += 1\n",
    "            if early_stop == args.early_stop:\n",
    "                logger.info(\"Early stop in {} epoch!\".format(epoch))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"adam_epsilon\": 1e-08, \n",
      "    \"dataset\": \"DuEE1.0\", \n",
      "    \"early_stop\": 5, \n",
      "    \"event_type\": \"trigger\", \n",
      "    \"learning_rate\": 1e-05, \n",
      "    \"linear_learning_rate\": 0.0001, \n",
      "    \"max_len\": 200, \n",
      "    \"model_name_or_path\": \"F:/prev_trained_model/chinese_wwm_pytorch\", \n",
      "    \"num_train_epochs\": 50, \n",
      "    \"output_dir\": \"../output\", \n",
      "    \"per_gpu_eval_batch_size\": 32, \n",
      "    \"per_gpu_train_batch_size\": 16, \n",
      "    \"seed\": 1, \n",
      "    \"weight_decay\": 0.01\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing...: 100%|███████████████████████████████████████████████████████████| 11958/11958 [00:07<00:00, 1613.53it/s]\n",
      "tokenizing...: 100%|███████████████████████████████████████████████████████████| 13915/13915 [00:09<00:00, 1511.94it/s]\n",
      "tokenizing...: 100%|█████████████████████████████████████████████████████████████| 1498/1498 [00:01<00:00, 1318.63it/s]\n",
      "tokenizing...: 100%|█████████████████████████████████████████████████████████████| 1790/1790 [00:01<00:00, 1467.18it/s]\n",
      "05/17/2021 17:17:08 - INFO - root -   The nums of the train_dataset features is 13915\n",
      "05/17/2021 17:17:08 - INFO - root -   The nums of the eval_dataset features is 1790\n"
     ]
    }
   ],
   "source": [
    "args=CFG()\n",
    "\n",
    "print(json.dumps(vars(args), sort_keys=True, indent=4, separators=(', ', ': '), ensure_ascii=False))\n",
    "init_logger(log_file=\".././log/{}.log\".format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())))\n",
    "seed_everything(args.seed)\n",
    "\n",
    "args.output_model_path = os.path.join(args.output_dir, args.dataset, args.event_type, \"best_model.pkl\")\n",
    "# 设置保存目录\n",
    "if not os.path.exists(os.path.dirname(args.output_model_path)):\n",
    "    os.makedirs(os.path.dirname(args.output_model_path))\n",
    "\n",
    "# device\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# dataset & dataloader\n",
    "# args.train_data = \"../data/{}/{}/train.tsv\".format(args.dataset, args.event_type)\n",
    "# args.dev_data = \"../data/{}/{}/dev.tsv\".format(args.dataset, args.event_type)\n",
    "# args.tag_path = \"../conf/{}/{}_tag.dict\".format(args.dataset, args.event_type)\n",
    "\n",
    "#trigger dataset\n",
    "args.trigger_train_data = \"../data/DuEE1.0/trigger/train.tsv\"\n",
    "args.trigger_dev_data = \"../data/DuEE1.0/trigger/dev.tsv\"\n",
    "args.trigger_tag_path = \"../conf/DuEE1.0/trigger_tag.dict\"\n",
    "\n",
    "#role dataset\n",
    "args.role_train_data = \"../data/DuEE1.0/role/train.tsv\"\n",
    "args.role_dev_data = \"../data/DuEE1.0/role/dev.tsv\"\n",
    "args.role_tag_path = \"../conf/DuEE1.0/role_tag.dict\"\n",
    "\n",
    "train_dataset = DuEEJointDataset(args,\n",
    "                                 args.trigger_train_data,\n",
    "                                 args.role_train_data,\n",
    "                                 args.trigger_tag_path,\n",
    "                                 args.role_tag_path,\n",
    "                                 tokenizer)\n",
    "\n",
    "eval_dataset = DuEEJointDataset(args,\n",
    "                                args.trigger_dev_data,\n",
    "                                args.role_dev_data,\n",
    "                                args.trigger_tag_path,\n",
    "                                args.role_tag_path,\n",
    "                                tokenizer)\n",
    "\n",
    "logger.info(\"The nums of the train_dataset features is {}\".format(len(train_dataset)))\n",
    "logger.info(\"The nums of the eval_dataset features is {}\".format(len(eval_dataset)))\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=args.per_gpu_train_batch_size,\n",
    "                        collate_fn=joint_collate_fn,\n",
    "                        num_workers=0)\n",
    "eval_iter = DataLoader(eval_dataset,\n",
    "                       shuffle=False,\n",
    "                       batch_size=args.per_gpu_eval_batch_size,\n",
    "                       collate_fn=joint_collate_fn,\n",
    "                       num_workers=0)\n",
    "\n",
    "# 用于evaluate\n",
    "args.tagger_id2label = train_dataset.tagger_dataset.label_vocab\n",
    "args.num_tagger_classes = len(args.tagger_id2label)\n",
    "tagegr_metric = ChunkEvaluator(label_list=args.tagger_id2label.keys(), suffix=False)\n",
    "\n",
    "args.role_id2label = train_dataset.role_dataset.label_vocab\n",
    "args.num_role_classes = len(args.role_id2label)\n",
    "role_metric = ChunkEvaluator(label_list=args.role_id2label.keys(), suffix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, eval_iter, model, tagger_metric,role_metric):\n",
    "    \"\"\"evaluate\"\"\"\n",
    "    tagger_metric.reset()\n",
    "    role_metric.reset()\n",
    "    batch_loss = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1).to(args.device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(eval_iter):\n",
    "            \n",
    "            for key in batch.keys():\n",
    "                batch[key] = batch[key].to(args.device)\n",
    "            tagger_logits,role_logits = model(\n",
    "            input_ids=batch['all_input_ids'],\n",
    "            attention_mask=batch['all_attention_mask'],\n",
    "            token_type_ids=batch['all_token_type_ids'],\n",
    "            )\n",
    "            #loss = criterion(logits.view(-1, args.num_classes),batch[\"all_labels\"].view(-1))\n",
    "            #batch_loss += loss.item()\n",
    "\n",
    "            \n",
    "            #tagger_preds = torch.argmax(tagger_logits, axis=-1)\n",
    "            tagger_preds=torch.tensor(model.tagger_crf.decode(tagger_logits),dtype=torch.int)\n",
    "            n_infer, n_label, n_correct = tagger_metric.compute(batch[\"all_seq_lens\"], tagger_preds, batch['all_tagger_labels'])\n",
    "            tagger_metric.update(n_infer, n_label, n_correct)\n",
    "            \n",
    "            #role_preds = torch.argmax(role_logits, axis=-1)\n",
    "            role_preds=torch.tensor(model.role_crf.decode(role_logits),dtype=torch.int)\n",
    "            n_infer, n_label, n_correct = role_metric.compute(batch[\"all_seq_lens\"], role_preds, batch['all_role_labels'])\n",
    "            role_metric.update(n_infer, n_label, n_correct)\n",
    "            \n",
    "    precision1, recall1, f1_score1 = tagger_metric.accumulate()\n",
    "    precision2, recall2, f1_score2 = role_metric.accumulate()\n",
    "\n",
    "    return precision1, recall1, f1_score1,precision2, recall2, f1_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "class DuEEEvent_joint_crf_model(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, num_tagger_classes,num_role_class):\n",
    "        super(DuEEEvent_joint_crf_model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_path)\n",
    "        self.tagger_classifier = nn.Linear(self.bert.config.hidden_size, num_tagger_classes)\n",
    "        self.role_classifier = nn.Linear(self.bert.config.hidden_size, num_role_class)\n",
    "        self.tagger_crf = CRF(num_tags=num_tagger_classes, batch_first=True)\n",
    "        self.role_crf = CRF(num_tags=num_role_class, batch_first=True)\n",
    "        \n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=None,\n",
    "                tagger_labels=None,\n",
    "                role_labels=None):\n",
    "        output = self.bert(input_ids,\n",
    "                           token_type_ids=token_type_ids,\n",
    "                           attention_mask=attention_mask)\n",
    "        sequence_output, pooled_output = output[0], output[1]\n",
    "        tagger_logits = self.tagger_classifier(sequence_output)\n",
    "        role_logits=self.role_classifier(sequence_output)\n",
    "        \n",
    "        if tagger_labels is not None and role_labels is not None:\n",
    "            loss1 = self.tagger_crf(emissions=tagger_logits, tags=tagger_labels, mask=attention_mask.to(torch.uint8))\n",
    "            loss2 = self.role_crf(emissions=role_logits, tags=role_labels, mask=attention_mask.to(torch.uint8))\n",
    "            loss=loss1+loss2\n",
    "            return -1 * loss\n",
    "        return tagger_logits,role_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DuEEEvent_joint_crf_model(args.model_name_or_path, num_tagger_classes=args.num_tagger_classes,num_role_class=args.num_role_classes)\n",
    "_=model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_iter, model):\n",
    "    logger.info(\"***** Running train *****\")\n",
    "    # 优化器\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    bert_param_optimizer = list(model.bert.named_parameters())\n",
    "    linear_param_optimizer = list(model.tagger_classifier.named_parameters())\n",
    "    \n",
    "    linear_param_optimizer.extend(list(model.role_classifier.named_parameters()))\n",
    "    \n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in bert_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay,\n",
    "         'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in bert_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0,\n",
    "         'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in linear_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': args.weight_decay,\n",
    "         'lr': args.linear_learning_rate},\n",
    "        {'params': [p for n, p in linear_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.0,\n",
    "         'lr': args.linear_learning_rate},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=args.learning_rate,\n",
    "                      eps=args.adam_epsilon)\n",
    "    # 损失函数\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1).to(args.device)\n",
    "    batch_loss = 0\n",
    "    pbar = ProgressBar(n_total=len(train_iter), desc='Training')\n",
    "    print(\"****\" * 20)\n",
    "    for step, batch in enumerate(train_iter):\n",
    "        for key in batch.keys():\n",
    "            batch[key] = batch[key].to(args.device)\n",
    "            \n",
    "        loss = model(\n",
    "            input_ids=batch['all_input_ids'],\n",
    "            attention_mask=batch['all_attention_mask'],\n",
    "            token_type_ids=batch['all_token_type_ids'],\n",
    "            tagger_labels=batch['all_tagger_labels'],\n",
    "            role_labels=batch['all_role_labels']\n",
    "        )\n",
    "\n",
    "        #tagger_logits = tagger_logits.view(-1, args.num_tagger_classes)\n",
    "        #role_logits = role_logits.view(-1, args.num_role_classes)\n",
    "        # 正常训练\n",
    "        #loss1 = criterion(tagger_logits, batch[\"all_tagger_labels\"].view(-1))\n",
    "        #loss2= criterion(role_logits, batch[\"all_role_labels\"].view(-1))\n",
    "        loss.backward()\n",
    "        #\n",
    "        batch_loss += loss.item()\n",
    "        pbar(step,\n",
    "             {\n",
    "                 'batch_loss': batch_loss / (step + 1),\n",
    "             })\n",
    "        optimizer.step()\n",
    "        model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2021 17:17:11 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 870/870 [==============================] 1.1s/step  batch_loss: 1149.5275    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2021 17:33:36 - INFO - root -   The trigger F1-score is 0.686014873934337 , the role F1-score is 0.39923183612504\n",
      "05/17/2021 17:33:36 - INFO - root -   the best trigger eval f1 is 0.6860 , role eval f1 is 0.3992, saving model !!\n",
      "05/17/2021 17:33:36 - INFO - root -   ***** Running train *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "[Training] 549/870 [=================>............] - ETA: 5:43  batch_loss: 442.1225  "
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "early_stop = 0\n",
    "for epoch, _ in enumerate(range(int(args.num_train_epochs))):\n",
    "    model.train()\n",
    "    train(args, train_iter, model)\n",
    "    eval_p, eval_r, eval_f1, eval_p2, eval_r2, eval_f12 = evaluate(args, eval_iter, model,tagegr_metric,role_metric)\n",
    "    logger.info(\n",
    "        \"The trigger F1-score is {} , the role F1-score is {}\".format(eval_f1,eval_f12)\n",
    "    )\n",
    "    \n",
    "    sumf1=eval_f1+eval_f12\n",
    "    if sumf1 > best_f1:\n",
    "        early_stop = 0\n",
    "        best_f1 = sumf1\n",
    "        logger.info(\"the best trigger eval f1 is {:.4f} , role eval f1 is {:.4f}, saving model !!\".format(eval_f1,eval_f12))\n",
    "        best_model = copy.deepcopy(model.module if hasattr(model, \"module\") else model)\n",
    "        torch.save(best_model.state_dict(), args.output_model_path)\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop == args.early_stop:\n",
    "            logger.info(\"Early stop in {} epoch!\".format(epoch))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
